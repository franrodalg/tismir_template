%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% @S@ SML
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Analysis of Benchmark Experiments in SML}\label{sec:sml}

Literature devoted to the formal analysis of benchmark classification
experiments, either in MCA or related disciplines, is quite scarce.
%
Some authors in Statistical Machine Learning (SML), however, have proposed 
approaches to the analysis of these experiments relying on conventional DoE
concepts.
%
To the best of our knowledge,
the work by \citet{EugsterPhD, Eugster2008ExpInf},
based on a framework previously proposed by \citet{Hothorn2005DABenchExp},
as well as a devoted chapter in \citet{AlpaydinIML},
represent the most notable efforts to this end.
%
In addition, within the context of Artificial Intelligence (AI)
\citet{CohenEMAI} provides a review of empirical methods
for the discipline that includes experimental design principles
and tools.

\citet{AlpaydinIML} introduces DoE terminology for an SML audience,
attempting to relate those concepts to conventional evaluation approaches
for learning algorithms,
as well as a brief review of performance metrics, assignment procedures,
and statistical inference tests, not unlike \citet{JapkowiczELA}.
%
It lacks, however, practical proposals on how to translate those
concepts into concrete measurement models to perform the inferential
analysis it advocates.

Eugster and collaborators%
~\cite{EugsterPhD, Eugster2008ExpInf, Hothorn2005DABenchExp},
on the other hand, propose a particular approach for 
the modelling and analysis of measurements, which allows to 
estimate the effects of different components of the experiment.
%
This aligns with our goals and serves as a basis for our own
proposals.
%
Therefore, in what follows we briefly review the analysis framework
they propose, adapting the notation when necessary to match our needs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% @S@ Eugster Review
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{SML Benchmark Experiments Analysis Framework}\label{sec:eugster}


The framework proposed in \citet{Hothorn2005DABenchExp} assumes
a data generation process (\emph{DGP}) is given,
from which we can draw $\SampNum$ independent and identically distributed
samples:
%
\begin{align}
  \begin{split}
    \SampLearn^1 =&{}~\ \{\Inst_1^1, \dots\}
      \sim DGP \\
    &{}\vdots \\
    \SampLearn^{\SampNum} =&{}~\ \{\Inst_1^{\SampNum},\dots\} 
      \sim DGP
\end{split}
\end{align}
%
Ideally, \emph{DGP} is a perfectly defined process from we can generate
as many samples as we require, as in a synthetic scenario.
%
In practice, however, we lack knowledge about \emph{DGP},
and we rely solely on a dataset 
$\Dataset = \{\Inst_1,\dots, \Inst_{\DatasetSize}\}~\sim~DGP$
of size $\DatasetSize$.
%
Standard practice in this case involves using resampling methods 
to mimic \emph{DGP}, such as subsampling, bootstrap or, 
$K$-fold cross-validation.
%
The authors in \citet{Hothorn2005DABenchExp, EugsterPhD} favour
bootstrap as resampling mechanism.


We consider $\AlgNum > 1$ candidate learning algorithms  
$\Alg_{\AlgIx}$ ($\AlgIx = 1, \dots, \AlgNum$).
%
For each algorithm, $\FittedModel$ 
denotes the model fit on a sample $\SampLearn^{\SampIx}$.
%
% This model conditions on the randomly drawn learning sample
% $\SampLearn^{\SampIx}$ from the data generating process $\emph{DGP}$.
% %
% Therefore, the model itself has a distribution $\AlgDist_{\AlgIx}$
% on the model space of $\Alg_{\AlgIx}$ which again depends on the data
% generating process \emph{DGP}:
% %
% \begin{align*}
%   \FittedModel \sim \AlgDist_{\AlgIx}(DGP),~\AlgIx = 1,\dots,\AlgNum
% \end{align*}
%
The scalar function $\PerfFun(\cdot)$ measures the theoretical performance
$\PerfFun_{\SampIx\AlgIx}$ of a fitted model $\FittedModel$,
which is a sample from the distribution of the performance measure
of $\Alg_\AlgIx$ accross all \emph{DGP}, denoted as $\PerfDist_\AlgIx(DGP)$:
%
\begin{align}
  \PerfFun_{\SampIx\AlgIx} = 
  \PerfFun(\Alg_\AlgIx,\SampLearn^{\SampIx}) \sim \PerfDist_\AlgIx(DGP).
\end{align}
%
% The scalar function $\PerfFun(\cdot)$ is freely definable to represent the
% performance of interest as a number.

For the particular case of supervised learning,
each instance $\Inst \in \SampLearn^{\SampIx}$
takes the form $\Inst = (\Label, \Feats)$,%
\footnote{%
  To improve readability, we omit the subscript 
  $\InstIx$ for $\Feats$, $\Label$, and $\Inst$.
}
where $\Feats$ represents a vector of features,
and $\Label$ denotes the corresponding annotation.
%
In this sense, $\LabelPred = \Alg_{\AlgIx}(\Feats~|~\SampLearn^{\SampIx})$
is the annotation predicted by the $j$-th model fitted on 
$\SampLearn^k$ given $\Feats$.
%
A scalar loss function $\LossFun(\Label, \LabelPred)$
measures the discrepancy between the annotation $\Label$ and the
prediction $\LabelPred$.
%
A summary functional $\SummFun_{\SampTest}(\cdot)$ then estimates
$\PerfFun_{\SampIx\AlgIx}$ from the individual results
of the loss function $\LossFun(\Label, \LabelPred)$ over the instances
of a validation sample $\SampTest^{\SampIx} \sim DGP$ 
associated with $\SampLearn^{\SampIx}$,
usually consisting on the instances in $\Dataset$ not included
in $\SampLearn^{\SampIx}$.
%
Moreover, 
we denote $\PerfMet_{\SampTest}(\cdot)$ the performance metric formed
by the composition of a loss function and the summary functional over
all the validation sample, so that:
%
\begin{align}
\begin{split}
  \hat{\PerfFun}_{\SampIx\AlgIx} &{}=
  \hat{\PerfFun}(\Alg_\AlgIx, \SampLearn^{\SampIx}) =
  \PerfMet_{\SampTest}(\Label, \LabelPred) = \\
  &{}= \SummFun_{\SampTest}(\LossFun(\Label, \Alg_{\AlgIx}
    (\Feats~|~\SampLearn^{\SampIx}))) 
  \sim \hat{\PerfDist}_{\AlgIx}(DGP),
  \end{split}
\end{align}
%
where $\hat{\PerfDist}_{\AlgIx}$ indicates the distribution of the
performance measure for algorithm $\Alg_{\AlgIx}$ in $\SampTest^{\SampIx}$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% @S@ Different Estimates of Performance
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% The performance measure is then defined by some functional 
% $\SummFun$ of the loss function's distribution over all observations
% of learning sample $\SampLearn^{\SampIx}$:
% \begin{align*}
%   \PerfFun_{\SampIx\AlgIx} = \PerfFun(\Alg_\AlgIx,\SampLearn^{\SampIx}) =
%   \SummFun(\LossFun(\Label, \Alg_{\AlgIx}(\Feats~|~\SampLearn^{\SampIx})))
%     \sim \PerfDist_{\AlgIx}(DGP)
% \end{align*}

% Now, $\PerfFun_{\SampIx\AlgIx}$ are samples drawn from the theoretical 
% performance distribution $\PerfDist_{\AlgIx}(DGP)$ of algorithm 
% $\Alg_{\AlgIx}$ on the data generating process \emph{DGP}.
% %
% In most cases we are not able to determine the theoretical performance 
% distribution analytically and we have to approximate it empirically.
% %
% The learning performance is an obvious first approximation:
% %
% \begin{align*}
%   \hat{\PerfFun}_{\SampIx\AlgIx} = 
%   \hat{\PerfFun}(\Alg_{\AlgIx},\SampLearn^{\SampIx}) = 
%   \hat{\SummFun}_{\SampLearn}(\LossFun(\Label, \Alg_{\AlgIx}
%   (\Feats~|~\SampLearn^{\SampIx}))) 
%   \sim \hat{\PerfDist}_{\AlgIx}(DGP)
% \end{align*}
% %
% $\hat{\SummFun}_{\SampLearn}$ denotes the empirical functional of the loss
% function's distribution over all observations of the corresponding
% learning sample.
% %
% $\hat{\PerfDist}_{\AlgIx}$ denotes in this case the algorithm's learning
% distribution function of the performance measure evaluated using 
% $\SampLearn^{\SampIx}~(\SampIx = 1, \dots , \SampNum)$.
% %
% Unfortunately learning performance is not a good estimate of the 
% generalization error 
% --as commonly known it would reward over-fitting.
% %
% Approaches based on independent test samples are the primary way of 
% approximating the theoretical performance distribution of an algorithm.

% Suppose that independent test samples $\SampTest^{\SampIx}$ with sufficient
% numbers of observations are drawn from the data generating 
% process \emph{DGP}.
% %
% An estimation of the generalization performance of algorithm $\Alg_{\AlgIx}$
% learned on learning sample $\SampLearn^{\SampIx}$ is then
% %
% \begin{align*}
%   \hat{\PerfFun}_{\SampIx\AlgIx} =
%   \hat{\PerfFun}(\Alg_\AlgIx, \SampLearn^{\SampIx}) =
%   \SummFun_{\SampTest}(\LossFun(\Label, \Alg_{\AlgIx}
%     (\Feats~|~\SampLearn^{\SampIx}))) 
%   \sim \hat{\PerfDist}_{\AlgIx}(DGP).
% \end{align*}
% %
% $\SummFun_{\SampTest}$ is the functional of the loss function's
% distribution over all observations of the corresponding test sample 
% $\SampTest^{\SampIx}$.
% %
% $\hat{\PerfDist}_{\AlgIx}$ denotes the algorithm's distribution function
% of the performance measure evaluated using $\SampTest^{\SampIx}$.
% %
% Dependent on the data situation the approximation of 
% $\PerfDist_{\AlgIx}$ by $\hat{\PerfDist}_{\AlgIx}$ is of different quality.
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% @S@ Analysis
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Defined in this way, then, a benchmark experiment generates
$\SampNum \times \AlgNum$ measurements that we intend to exploit to rank 
the $\AlgNum$ candidate algorithms $\Alg_{\AlgIx}$ according to the
distribution of their estimated performance $\hat{\PerfDist}_{\AlgIx}$.
%
A common approach in much published literature involves computing
a descriptive statistic $\PerfDesc(\cdot)$ over the $\SampNum$
measurements corresponding to each algorithm $\Alg_{\AlgIx}$,
and then compare the computed values.
%
The functional $\PerfDesc$ often consists on a measure of central
tendency, such as mean or median, but other options, such as
minimum, maximum, or dispersion measures, also appear in
the literature.
%
Relying on this criterion,
researchers consider $\Alg_{\AlgIx}$ preferrable over
$\Alg_{\AlgIx'}$  if
$\PerfDesc(\hat{\PerfDist}_{\AlgIx}) < \PerfDesc(\hat{\PerfDist}_{\AlgIx'})$
(or
$\PerfDesc(\hat{\PerfDist}_{\AlgIx}) > \PerfDesc(\hat{\PerfDist}_{\AlgIx'})$
if 
$\PerfFun(\cdot)$ measures agreement instead of discrepancy).
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% @S@ Inference
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This simple analysis approach above, however, does not provide any
support regarding whether observed differences actually arise from
differences in the performance of the learning algorithms under study.
%
Inferential statistics, on the other hand, provides tools to this end.
%
Nevertheless, applying these tools involves making assumptions,
such as posing a model for the measurements.
%
In this sense, \citet{EugsterPhD, Eugster2008ExpInf}
considers the benchmark experiment we described resembles a 
\emph{block design} from conventional DoE,
and proposes the following measurement model:
%
\begin{align}
  \begin{split}
    \PerfFun_{\SampIx\AlgIx} =
      \EffectTreat_0 +
        \EffectTreat_{\AlgIx} + 
        \EffectBlock_{\SampIx} +
        \Residual_{\SampIx\AlgIx},\\%
    \SampIx =  1, \dots , \SampNum,~\AlgIx = 1, \dots, (\AlgNum - 1),
    \label{eq:rbd}
  \end{split}
\end{align}
%
with the effect of the candidate algorithms,
the \emph{treatments} of the experiment, 
represented as $\EffectTreat_{\AlgIx}$,
and the effect of the samples, the \emph{blocks} of the experiment,
modelled as $\EffectBlock_{\SampIx}$.
%
In addition, $\EffectTreat_0$ here denotes the performance of a 
baseline algorithm,
implying the $\EffectTreat_{\AlgIx}$ reflect differential effects
against this baseline.
%
Note the model only includes explicitly $\AlgNum-1$ parameters to 
represent the effects of the $\AlgNum$ algorithms under study,
as one of them takes the role of baseline algorithm and, thus,
$\EffectTreat_{0}$ captures its effect.
%
We briefly discuss this approach in Sec.~\ref{sec:mixed} below.
%
Finally, the residual $\Residual_{\SampIx\AlgIx}$ reflects all
variability not explained by the previously described effects.

The null hypothesis of interest considers no difference between
the effects of the algorithms in performance:
%
\begin{align}
  \begin{split}
    H_0 &{}:~\EffectTreat_1 = \cdots = \EffectTreat_{\AlgNum - 1} = 0.\\
    % H_A &{}:~\exists \AlgIx~:~\EffectTreat_\AlgIx \neq 0.
  \end{split}
\end{align}
%
Literature in SML evaluation often encourages using non-parametric approaches
to test hypotheses on measurements obtained from this kind of 
experiment, as it is not always clear usual assumptions 
for parametric tests hold (see \citet{JapkowiczELA}, for instance).
%
In this sense, tests such as Friedman and Wilcoxon-Nemenyi-McDonald-Thompson
allow us to check the hypothesis of interest with less restrictive
requirements about the distribution of measurements,
but still contingent on the sampling procedure.

Non-parametric tests, however, do not provide estimates for the effects
parametrised in the model above, namely, %
$\EffectTreat_{\AlgIx}$, 
$\EffectBlock_{\SampIx}$ and 
$\Residual_{\SampIx\AlgIx}$.
%
In this regard, Eugster argues that the possibility of drawing an
arbitrarily large number $\SampNum$ of samples allows us to assume the
requirements for parametric tests are asymptotically satisfied.
%
He then proposes interpreting model~\ref{eq:rbd} as expressing
mixed effects, this is,
$\EffectTreat_{\AlgIx}$ as a fixed effect,
and $\EffectBlock_{\SampIx}$ as a random effect,
with $\EffectBlock_{\SampIx} \sim \Norm(0,\var_{\SampIx})$
and $\Residual_{\AlgIx\SampIx} \sim \Norm(0, \var)$.
%
Moreover, he suggests using ANOVA to perform a global test to
determine whether there exist differences between the algorithms
not caused by the samples,
%
as well as Tukey contrasts to identify which particular algorithms
actually differ, if any.

Finally, \citet{EugsterPhD} also considers experiments involving a collection
of datasets -- a \emph{domain} 
$\Domain = \{\Dataset_1,\dots, \Dataset_\DatasetNum\}$.
%
In this case, he proposes the following measurement model:
%
\begin{align}
  \begin{split}
  \PerfFun_{\DatasetIx\SampIx\AlgIx} =
    \EffectTreat_{\AlgIx} + \EffectBlock_{\DatasetIx} +
    \EffectBlock_{\DatasetIx\AlgIx} + \EffectBlock_{\DatasetIx\SampIx} +
    \Residual_{\DatasetIx\SampIx\AlgIx},\\
  \DatasetIx = 1,\dots,\DatasetNum,~%
    \SampIx = 1,\dots,\SampNum,~%
    \AlgIx = 1,\dots,\AlgNum,
  \end{split}
  \label{eq:domain}
\end{align}
%
with $\EffectTreat_{\AlgIx}$ denoting the algorithm's fixed effect, and
$\EffectBlock_{\DatasetIx}$ expressing the random effect introduced
by dataset $\Dataset_{\DatasetIx}$, which he suggests we interpret
as the complexity of the dataset.
%
Moreover, the parameter $\EffectBlock_{\DatasetIx\AlgIx}$ 
reflects a potential interaction between dataset and algorithm,
which should be regarded as a random effect, and
we can interpret as the difference between the overall
mean effect of algorithm $\Alg_{\AlgIx}$ and the particular effect of the 
same algorithm in dataset $\Dataset_{\DatasetIx}$.
%
The interaction parameter $\EffectBlock_{\DatasetIx\SampIx}$ 
is also modelled as a random effect, and reflects the effect
of individual samples within a dataset.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% @S@ Mixed Effects Models
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Comments on Eugster's Models}\label{sec:mixed}

The model proposed in~\citet{EugsterPhD}
for inferential analysis of the measurements of single-domain
benchmark experiments in SML we presented in
Eq.~\ref{eq:rbd} includes a parameter $\EffectTreat_{0}$ for 
the effect of a baseline algorithm and
$\AlgNum-1$ parameters $\EffectTreat_{\AlgIx}$ that capture
the differential contributions of the remainder algorithms
under study against the baseline.
%
This is not the approach in conventional DoE.

Most texts in the discipline present a similar, but different model,
usually referred to as the ``means model'' \citep{MontgomeryDAE},
which would be expressed as
%
\begin{align}
  \begin{split}
    \PerfFun_{\SampIx\AlgIx} = \mu + \dot{\EffectTreat}_{\AlgIx} + 
      \EffectBlock_{\SampIx} + \Residual_{\SampIx\AlgIx},\\
    \SampIx = 1,\dots,\SampNum,~\AlgIx = 1,\dots,\AlgNum.
    \label{eq:cbd_means}
  \end{split}
\end{align}
%
The parameter $\mu$ in this version represents the ``grand mean'' of the
measurements across all observations in the experiment,
and replaces the baseline treatment effect in the model proposed by Eugster,
leading to $\AlgNum$ differential treatment effects instead of $\AlgNum - 1$.
%
This treatment effects $\dot{\EffectTreat}_{\AlgIx}$ in this case all 
represent differences with respect to the grand mean instead of
a particular algorithm.

As a minor aside, note that the model in Eq.~\ref{eq:domain} does
not include a baseline effect, but instead $\AlgNum$ explicit parameters 
for the contributions of the algorithms under study.
%
Even though these treatment effects are not differential
contributions, as opposed to those in Eq.~\ref{eq:rbd},
Eugster uses exactly the same notation in both cases.
%
We avoid this abuse of notation by writing $\dot{\EffectTreat}$,
with a dot on top, when the parameter reflects differential instead of
absolute effect.

The idea of considering one of the candidate algorithms as
baseline certainly makes sense and relates to normal practice
in both SML and MCA research,
e.g., comparing newly proposed solutions against either a hypothetical 
random prediction baseline or the current state of the art.
%
Unfortunately, the estimation procedures that appear in conventional
DoE texts
seem to rely on the introduction of the global mean term.
%
It is not clear yet whether they would easily adapt for models 
that include a baseline treatment effect parameter.
%
In this sense, Eugster does not provide details of how he computes
parameter estimations in the example he develops accompanying
the model.

In principle, models~\ref{eq:rbd} and~\ref{eq:cbd_means} relate easily.
%
More precisely, we see 
$\EffectTreat_{0} = \mu + \dot{\EffectTreat}_{\AlgNum}$.
%
This means we can effortlessly translate parameter estimates from one
version to the other according to our needs in that scenario.
%
Other scenarios, however, might prove more difficult,
as the lack of baseline parameter in model~\ref{eq:domain},
which introduces interaction effects, seems to imply. 
%
For these reasons, regarding the choice between a baseline treatment
or overall mean effect parameter,
at this point we favour the conventional means model 
in Eq.~\ref{eq:cbd_means} over Eugster's proposal as a basis for our work,
%
despite the arguably greater appeal of an explicit baseline estimate 
than a not so meaningful average effect.

Another aspect of the models proposed by Eugster we think worth
commenting involves the introduction of interaction effects between
treatments, whith fixed effects, and blocks, with random effects,
such as the algorithm-dataset interaction reflected in parameter
$\EffectBlock_{\DatasetIx\AlgIx}$.
%
\citet{BaileyDCE} explicitly rejects this possibility,
claiming it breaks basic assumptions of the framework she introduces,
and suggesting it
``may be better to analyse such an experiment as [\dots] different
experiments, one for each [block], with no intention of generalising
the results to other [blocks]'' (pg. 280).

Other authors, however, are more lenient.
%
\citet{PinheiroMEMS}, the reference
cited in \citep{EugsterPhD} for this topic,
as well as \citet{MontgomeryDAE},
allow interactions between treatment and block factors
in mixed models, which they regard as yielding random effects.
%
\citet{NeterALSM} and \citet{CobbIDAE},
on the other hand, distinguish between ``unrestricted'' and 
``restricted'' models, in which interactions between blocks
and treatment factors produce random or fixed effects, respectively.
%
\citet{CobbIDAE} and  Langley \citet{LawsonDAER} describe
\emph{generalised complete block design} (GCBD) as 
an extension of the conventional \emph{complete block design} (CBD)
that allows multiple replicates
of each level of the treatment factor per block,
thus sparing degrees of freedom for estimating potential 
block-treatment interaction effects.

Overall, we find the vast majority of texts we have reviewed consider
block-treatment interactions acceptable,
with some which do not discuss this possibility,
at least explicitly, at all 
(e.g., \citet{MasonSDAE} and \citet{ChengTFD}).
%
It is not completely clear, at this stage, why \citet{BaileyDCE}
discourages this practice.
%
In the future, we will embrace the position taken by Eugster and
many other DoE authors, and include block-treatment interactions when
necessary.
%
We should, however, remain vigilant not to break basic assumptions
of the estimation and inference approaches we adopt.
%
This might involve reconsider to which extent we can apply
the orthogonal vector space decomposition technique of 
\citet{BaileyDCE}.


% A MORE SUBTLE ISSUE: INSTANCES AS OBSERVATIONAL UNITS


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% @S@ Discussion
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Discussion}\label{sec:background-dis}

The analysis framework reviewed above seems to provide
a promising starting point for our own goals,
in spite of the comments in Sec.~\ref{sec:mixed}.
%
In particular, the modelling of the contributions of learning algorithm 
and sample as fixed and random effects, respectively, should almost
directly apply in our context.
%
For most scenarios we regard here, however,
we would need to replace learning algorithm with the overall method that
includes the feature extraction step as treatment factor.

We should take into consideration some important differences between
SML and MCA research, though.
%
First and foremost, the latent ability we aim to assess obviously differs.
%
SML concerns \emph{learning} \citep{HernandezOrallo2016Eval},
thus success relies on identifying patterns in the training data that
remain in validation, whatever those might be.
%
On the other hand, from our point of view, in MCA the target concept
plays the central role, and the data-driven approach usually employed
should only be regarded as a means towards and end, and not the end
in itself.
%
The main practical consequence of this distinction is the population
we aim to generalise the results to.
%
% Convenience sample?
%
In our opinion, this requires analysis approaches that go beyond
the usual benchmark experiments.
%

Even ignoring the inherent differences in purpose, 
we find practical disparities that impact which elements
we should include in our analysis.
%
The most obvious difference in this sense is the nature of the data
involved.
%
Whereas SML assumes the feature representation in the given sample
contains relevant measurements to detect patterns,
much MCA research focuses in determining which and how to perform such
measurements from raw data in the first place.
%
This means that we might need to consider common characteristics of the
raw data as potential effects to estimate.
%
This also impacts the structure in the treatments we should consider.
%
In particular, we might be interested in isolating the effects of the
feature extractor from those of the learning algorithm
instead of handle them as a single entity, in order to
assess the success of the measurements performed from the raw data.
%
These issues, among others, affect how we formalise the analysis
framework, as we will see in the following sections.
